---
slug: local-run-llama-3-2-with-continue
title: ä½¿ç”¨ Continue å’Œ LLama 3.2ï¼šæœ¬åœ°åŒ–å¤§æ¨¡å‹çš„é‹è¡Œèˆ‡æ‡‰ç”¨
description: æœ¬ç¯‡æ–‡ç« å°‡ä»‹ç´¹å¦‚ä½•çµåˆ Continue æ¡†æ¶èˆ‡ LLaMA 3.2 æ¨¡å‹ï¼Œå¯¦ç¾æœ¬åœ°åŒ–å¤§èªè¨€æ¨¡å‹çš„é‹è¡Œèˆ‡æ‡‰ç”¨ã€‚å¾ç’°å¢ƒè¨­ç½®ã€æ¨¡å‹ä¸‹è¼‰ï¼Œåˆ°å¯¦éš›æ‡‰ç”¨çš„æ­¥é©Ÿè§£æï¼Œå¹«åŠ©é–‹ç™¼è€…åœ¨ä¸ä¾è³´é›²ç«¯çš„æƒ…æ³ä¸‹ï¼Œå……åˆ†åˆ©ç”¨å¤§æ¨¡å‹çš„èƒ½åŠ›é€²è¡Œè‡ªç„¶èªè¨€è™•ç†ä»»å‹™ã€‚æˆ‘å€‘é‚„å°‡æ¢è¨æœ¬åœ°åŒ–é‹è¡Œçš„å„ªå‹¢èˆ‡æŒ‘æˆ°ï¼Œä¸¦æä¾›å¯¦éš›æ‡‰ç”¨å ´æ™¯çš„æ¡ˆä¾‹åˆ†æã€‚
authors: [junminhong]
keywords: [
  "LLama 3.2",
  "Continue plugin",
  "æœ¬åœ°åŒ–å¤§æ¨¡å‹",
  "AI æ¨¡å‹é‹è¡Œ",
  "è‡ªç„¶èªè¨€è™•ç†",
  "Cursor æ›¿ä»£å“"
]
tags: [LLama, Continue]
---

## [LLama 3.2](https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/) æ¨¡å‹ä»‹ç´¹
Meta åœ¨ 2024 å¹´ä¹æœˆç™¼ä½ˆäº† LLaMA 3.2ï¼Œé€™æ˜¯é‡å°å¤§èªè¨€æ¨¡å‹æŠ€è¡“çš„ä¸€æ¬¡é‡è¦å‡ç´š

èˆ‡ä»¥å¾€ç‰ˆæœ¬ç›¸æ¯”ï¼ŒLLaMA 3.2 æä¾›äº†æ›´é«˜æ•ˆçš„æ¨ç†èƒ½åŠ›ã€æ›´å¥½çš„è¨˜æ†¶æ•ˆæœï¼Œä¸¦ä¸”åœ¨å¤šç¨®è‡ªç„¶èªè¨€è™•ç†ï¼ˆNLPï¼‰ä»»å‹™ä¸Šå±•ç¤ºäº†å¼·å¤§çš„è¡¨ç¾

ä¸è«–æ˜¯ç”Ÿæˆæ–‡æœ¬ã€é€²è¡Œå°è©±é‚„æ˜¯è™•ç†è¤‡é›œçš„ä»»å‹™ï¼ŒLLaMA 3.2 éƒ½å…·æœ‰æ›´å„ªç§€çš„ç²¾åº¦å’Œé€Ÿåº¦

LLaMA 3.2 é‚„æ”¯æ´é‚Šç·£è¨­å‚™èˆ‡ç§»å‹•ç«¯çš„é‹è¡Œï¼Œé€™ä½¿å¾—å®ƒæˆç‚ºä¼æ¥­å¯¦ç¾é«˜æ•ˆèƒ½ã€æœ¬åœ°åŒ–å¤§æ¨¡å‹æ‡‰ç”¨çš„ç†æƒ³é¸æ“‡

## åœ¨ Docker ä¸­é‹è¡Œ llama 3.2 3B
> ğŸ’¡ é€™é‚Šè¦æ³¨æ„ docker ç’°å¢ƒçš„è³‡æºè¨˜æ†¶é«”è¦çµ¦å¤ ï¼Œä¸ç„¶æ¨¡å‹æœƒå•Ÿå‹•ä¸äº†

é€™æ¬¡æˆ‘å€‘ä½¿ç”¨ docker ä¾†å¿«é€Ÿé‹è¡Œ llama 3.2 3B æ¨¡å‹ï¼Œå¦‚æœé›»è…¦è¦æ ¼å¤ åŠ›çš„è©±å¯ä»¥è€ƒæ…®ä½¿ç”¨ 11B æˆ– 90B çš„æ¨¡å‹
ç‚ºäº†ç°¡åŒ–æ¨¡å‹çš„éƒ¨ç½²å’Œé‹è¡Œï¼Œæˆ‘å€‘å¯ä»¥é€šé Docker ä¾†æ§‹å»ºé‹è¡Œç’°å¢ƒ

### å¾ Docker Hub ä¸‹è¼‰ [ollama](https://hub.docker.com/r/ollama/ollama) çš„ image
```
# å¾ docker hub ä¸‹è¼‰ docker imageï¼Œä¸¦ä¸”åœ¨èƒŒæ™¯å•Ÿå‹•
docker run -d -p 11434:11434 --name ollama ollama/ollama

# å¾å‰›å‰›çš„ ollama container ä¸­ä¸‹è¼‰ llama3.2 3B æ¨¡å‹ï¼Œä¸¦ä¸”åœ¨èƒŒæ™¯å•Ÿå‹•
# å› ç‚ºæ¨¡å‹å…·æœ‰ä¸€å®šçš„å¤§å°ï¼Œæ‰€ä»¥éœ€è¦èŠ±é»æ™‚é–“ç­‰å¾…ä¸‹è¼‰
docker exec -d -it ollama ollama run llama3.2:3b

# å‡è¨­å¦‚æœä½ æƒ³å…ˆä½¿ç”¨å°è©±çš„è©±å¯ä»¥ä¸é€²èƒŒæ™¯
docker exec -it ollama ollama run llama3.2:3b
```

## VSCode çµåˆ ollama é€²è¡Œ AI èŠå¤©ä»¥åŠç¨‹å¼ç¢¼ç”Ÿæˆ
ç”¨å€‹ [Continue](https://marketplace.visualstudio.com/items?itemName=Continue.continue) é¦¬ä¸Šè®“ä½ çš„ VScode æ–èº«ä¸€è®Šæˆæœ€è¿‘å¾ˆç«ç´…çš„ Cursor

### å®‰è£ [Continue](https://marketplace.visualstudio.com/items?itemName=Continue.continue)
ç›´æ¥æŠŠé€™å€‹ plugin ä¸‹è¼‰ä¸‹ä¾†å¾Œï¼Œå°‡ä¸‹é¢é€™å€‹ config è¤‡è£½è²¼ä¸Šï¼Œå³å¯é–‹å§‹è‡ªç”±ç™¼æ®
```
{
  "models": [
    { 
      "title" : "Llama 3.2 3b" , 
      "provider" : "ollama" , 
      "model" : "llama3.2:3b" 
    } 
  ],
  "embeddingsProvider" :  { 
    "provider" :  "ollama" , 
    "model" :  "nomic-embed-text" 
  }, 
  "tabAutocompleteModel": {
    "title" : "Llama 3.2 3b" , 
    "provider" : "ollama" , 
    "model" : "llama3.2:3b" 
  }
}
```

## Model Benchmarks
![](https://scontent.ftpe8-4.fna.fbcdn.net/v/t39.2365-6/461288018_1255239495501495_271827633811450582_n.png?_nc_cat=102&ccb=1-7&_nc_sid=e280be&_nc_ohc=Cz_bhxFeFp4Q7kNvgEt3GYz&_nc_zt=14&_nc_ht=scontent.ftpe8-4.fna&_nc_gid=AlG84r8SnW_5Wv4YEdxW6ku&oh=00_AYAEoTFe6Um54vhIu-0i9xJemcRXgGrrlZlN7ooIoBqAww&oe=6728D1ED)
![](https://scontent.ftpe8-2.fna.fbcdn.net/v/t39.2365-6/461157789_931406385491961_1692349435372036848_n.png?_nc_cat=100&ccb=1-7&_nc_sid=e280be&_nc_ohc=WcgKBCDOK8IQ7kNvgFW6Svy&_nc_zt=14&_nc_ht=scontent.ftpe8-2.fna&_nc_gid=AlG84r8SnW_5Wv4YEdxW6ku&oh=00_AYAPUM4Xbauw5F5XC_l2a4HfzgSUU95b19q_zQA18WVCfw&oe=6728E958)

## æ³¨æ„äº‹é …
- å¦‚æœè‡ªå·±æ¶è¨­æ¨¡å‹ï¼Œæœƒéå¸¸åƒé›»è…¦è³‡æºï¼Œæ‰€ä»¥å¯©æ…è©•ä¼°å¾Œå†ä½¿ç”¨

## åƒè€ƒé€£çµ
- [https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/](https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/)
- [https://hub.docker.com/r/ollama/ollama](https://hub.docker.com/r/ollama/ollama)
- [https://marketplace.visualstudio.com/items?itemName=Continue.continue](https://marketplace.visualstudio.com/items?itemName=Continue.continue)